{"Collected Steps per Second": 1346.709538392708, "Cumulative Model Updates": 146, "Cumulative Timesteps": 2550344, "Mean KL Divergence": 0.0, "Overall Steps per Second": 1286.7680491138983, "PPO Batch Consumption Time": 0.5603847503662109, "Policy Entropy": 0.6931439638137817, "Policy Reward": 0.09201288496632445, "Policy Update Magnitude": 0.02692166343331337, "SB3 Clip Fraction": 0.0, "Timestep Collection Time": 37.1275309, "Timestep Consumption Time": 1.7295110000000022, "Timesteps Collected": 50000, "Total Iteration Time": 38.8570419, "Value Function Loss": 0.004912246484309435, "Value Function Update Magnitude": 0.02120980992913246, "_runtime": 582.6278748512268, "_step": 103, "_timestamp": 1724193084.7965498, "x_vel": -4.305742599699949, "y_vel": 573.8523408867741, "z_vel": 12.243954947757722}