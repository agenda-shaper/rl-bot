Created new wandb run! b2ecbwm8
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06336
Policy Entropy: 0.84265
Value Function Loss: nan
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10602
Value Function Update Magnitude: 0.10436
Collected Steps per Second: 6,556.70894
Overall Steps per Second: 5,015.59904
Timestep Collection Time: 7.62608
Timestep Consumption Time: 2.34322
PPO Batch Consumption Time: 0.69531
Total Iteration Time: 9.96930
Cumulative Model Updates: 1
Cumulative Timesteps: 50,002
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05481
Policy Entropy: 0.83569
Value Function Loss: 0.45953
Mean KL Divergence: 0.00080
SB3 Clip Fraction: 0.00010
Policy Update Magnitude: 0.08407
Value Function Update Magnitude: 0.07153
Collected Steps per Second: 5,769.71931
Overall Steps per Second: 4,613.43546
Timestep Collection Time: 8.66663
Timestep Consumption Time: 2.17215
PPO Batch Consumption Time: 0.67413
Total Iteration Time: 10.83878
Cumulative Model Updates: 2
Cumulative Timesteps: 100,006
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 100006...
Checkpoint 100006 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07210
Policy Entropy: 0.83350
Value Function Loss: 0.57998
Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.04156
Policy Update Magnitude: 0.12852
Value Function Update Magnitude: 0.15434
Collected Steps per Second: 6,549.34557
Overall Steps per Second: 4,760.20392
Timestep Collection Time: 7.63618
Timestep Consumption Time: 2.87009
PPO Batch Consumption Time: 0.63982
Total Iteration Time: 10.50627
Cumulative Model Updates: 4
Cumulative Timesteps: 150,018
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06432
Policy Entropy: 0.83551
Value Function Loss: 0.79198
Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.01061
Policy Update Magnitude: 0.16918
Value Function Update Magnitude: 0.23201
Collected Steps per Second: 6,849.83672
Overall Steps per Second: 4,696.59901
Timestep Collection Time: 7.30032
Timestep Consumption Time: 3.34696
PPO Batch Consumption Time: 0.59391
Total Iteration Time: 10.64728
Cumulative Model Updates: 7
Cumulative Timesteps: 200,024
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 200024...
Checkpoint 200024 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03194
Policy Entropy: 0.84130
Value Function Loss: 0.98163
Mean KL Divergence: 0.00174
SB3 Clip Fraction: 0.00451
Policy Update Magnitude: 0.15668
Value Function Update Magnitude: 0.23557
Collected Steps per Second: 6,522.22705
Overall Steps per Second: 4,608.79401
Timestep Collection Time: 7.66793
Timestep Consumption Time: 3.18350
PPO Batch Consumption Time: 0.58027
Total Iteration Time: 10.85143
Cumulative Model Updates: 10
Cumulative Timesteps: 250,036
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05910
Policy Entropy: 0.84977
Value Function Loss: 1.11748
Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.02075
Policy Update Magnitude: 0.15344
Value Function Update Magnitude: 0.24086
Collected Steps per Second: 6,865.31599
Overall Steps per Second: 4,782.53444
Timestep Collection Time: 7.28503
Timestep Consumption Time: 3.17261
PPO Batch Consumption Time: 0.56063
Total Iteration Time: 10.45764
Cumulative Model Updates: 13
Cumulative Timesteps: 300,050
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 300050...
Checkpoint 300050 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02612
Policy Entropy: 0.86131
Value Function Loss: 1.34222
Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.01998
Policy Update Magnitude: 0.15439
Value Function Update Magnitude: 0.25063
Collected Steps per Second: 6,595.23699
Overall Steps per Second: 4,641.45309
Timestep Collection Time: 7.58305
Timestep Consumption Time: 3.19203
PPO Batch Consumption Time: 0.57751
Total Iteration Time: 10.77507
Cumulative Model Updates: 16
Cumulative Timesteps: 350,062
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02233
Policy Entropy: 0.87370
Value Function Loss: 1.46487
Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.01623
Policy Update Magnitude: 0.16120
Value Function Update Magnitude: 0.26252
Collected Steps per Second: 6,847.22120
Overall Steps per Second: 4,792.35015
Timestep Collection Time: 7.30311
Timestep Consumption Time: 3.13144
PPO Batch Consumption Time: 0.55214
Total Iteration Time: 10.43455
Cumulative Model Updates: 19
Cumulative Timesteps: 400,068
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 400068...
Checkpoint 400068 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00130
Policy Entropy: 0.88575
Value Function Loss: 1.05273
Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.02537
Policy Update Magnitude: 0.16015
Value Function Update Magnitude: 0.26414
Collected Steps per Second: 6,882.34154
Overall Steps per Second: 4,838.95863
Timestep Collection Time: 7.26497
Timestep Consumption Time: 3.06783
PPO Batch Consumption Time: 0.53816
Total Iteration Time: 10.33280
Cumulative Model Updates: 22
Cumulative Timesteps: 450,068
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02287
Policy Entropy: 0.88492
Value Function Loss: 0.59495
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.01731
Policy Update Magnitude: 0.14867
Value Function Update Magnitude: 0.23883
Collected Steps per Second: 6,831.47429
Overall Steps per Second: 4,847.33112
Timestep Collection Time: 7.32111
Timestep Consumption Time: 2.99673
PPO Batch Consumption Time: 0.52605
Total Iteration Time: 10.31784
Cumulative Model Updates: 25
Cumulative Timesteps: 500,082
Timesteps Collected: 50,014
--------END ITERATION REPORT--------
Saving checkpoint 500082...
Checkpoint 500082 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00134
Policy Entropy: 0.86862
Value Function Loss: 0.05409
Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.04476
Policy Update Magnitude: 0.12216
Value Function Update Magnitude: 0.17548
Collected Steps per Second: 6,806.40537
Overall Steps per Second: 4,756.89377
Timestep Collection Time: 7.34690
Timestep Consumption Time: 3.16542
PPO Batch Consumption Time: 0.56742
Total Iteration Time: 10.51232
Cumulative Model Updates: 28
Cumulative Timesteps: 550,088
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.16541
Policy Entropy: 0.83709
Value Function Loss: 0.04633
Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.14808
Policy Update Magnitude: 0.10191
Value Function Update Magnitude: 0.16350
Collected Steps per Second: 6,930.20864
Overall Steps per Second: 4,819.82097
Timestep Collection Time: 7.21479
Timestep Consumption Time: 3.15904
PPO Batch Consumption Time: 0.56273
Total Iteration Time: 10.37383
Cumulative Model Updates: 31
Cumulative Timesteps: 600,088
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 600088...
Checkpoint 600088 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10255
Policy Entropy: 0.81795
Value Function Loss: 0.04628
Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.12941
Policy Update Magnitude: 0.08661
Value Function Update Magnitude: 0.16008
Collected Steps per Second: 6,714.95543
Overall Steps per Second: 4,787.06837
Timestep Collection Time: 7.44607
Timestep Consumption Time: 2.99874
PPO Batch Consumption Time: 0.53989
Total Iteration Time: 10.44481
Cumulative Model Updates: 34
Cumulative Timesteps: 650,088
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00379
Policy Entropy: 0.81728
Value Function Loss: 0.04190
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03553
Policy Update Magnitude: 0.08251
Value Function Update Magnitude: 0.14453
Collected Steps per Second: 7,062.70554
Overall Steps per Second: 4,857.74981
Timestep Collection Time: 7.08057
Timestep Consumption Time: 3.21391
PPO Batch Consumption Time: 0.57938
Total Iteration Time: 10.29448
Cumulative Model Updates: 37
Cumulative Timesteps: 700,096
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 700096...
Checkpoint 700096 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01029
Policy Entropy: 0.81433
Value Function Loss: 0.04517
Mean KL Divergence: 0.00112
SB3 Clip Fraction: 0.00243
Policy Update Magnitude: 0.08484
Value Function Update Magnitude: 0.12569
Collected Steps per Second: 6,770.90326
Overall Steps per Second: 4,775.13157
Timestep Collection Time: 7.38483
Timestep Consumption Time: 3.08650
PPO Batch Consumption Time: 0.54611
Total Iteration Time: 10.47133
Cumulative Model Updates: 40
Cumulative Timesteps: 750,098
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02556
Policy Entropy: 0.80273
Value Function Loss: 0.03512
Mean KL Divergence: 0.00149
SB3 Clip Fraction: 0.00431
Policy Update Magnitude: 0.08681
Value Function Update Magnitude: 0.11109
Collected Steps per Second: 7,024.62527
Overall Steps per Second: 4,913.88949
Timestep Collection Time: 7.11782
Timestep Consumption Time: 3.05742
PPO Batch Consumption Time: 0.53389
Total Iteration Time: 10.17524
Cumulative Model Updates: 43
Cumulative Timesteps: 800,098
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
Saving checkpoint 800098...
Checkpoint 800098 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05195
Policy Entropy: 0.78804
Value Function Loss: 0.03065
Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.02627
Policy Update Magnitude: 0.08040
Value Function Update Magnitude: 0.09847
Collected Steps per Second: 6,879.67233
Overall Steps per Second: 4,751.72376
Timestep Collection Time: 7.26779
Timestep Consumption Time: 3.25471
PPO Batch Consumption Time: 0.58167
Total Iteration Time: 10.52250
Cumulative Model Updates: 46
Cumulative Timesteps: 850,098
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00904
Policy Entropy: 0.77557
Value Function Loss: 0.01955
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03074
Policy Update Magnitude: 0.07119
Value Function Update Magnitude: 0.08362
Collected Steps per Second: 6,311.33688
Overall Steps per Second: 4,543.01013
Timestep Collection Time: 7.92257
Timestep Consumption Time: 3.08379
PPO Batch Consumption Time: 0.55150
Total Iteration Time: 11.00636
Cumulative Model Updates: 49
Cumulative Timesteps: 900,100
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 900100...
Checkpoint 900100 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00746
Policy Entropy: 0.76410
Value Function Loss: 0.01447
Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.01928
Policy Update Magnitude: 0.06612
Value Function Update Magnitude: 0.06999
Collected Steps per Second: 6,527.55162
Overall Steps per Second: 4,628.78043
Timestep Collection Time: 7.66229
Timestep Consumption Time: 3.14315
PPO Batch Consumption Time: 0.55833
Total Iteration Time: 10.80544
Cumulative Model Updates: 52
Cumulative Timesteps: 950,116
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03801
Policy Entropy: 0.75064
Value Function Loss: 0.01467
Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.01614
Policy Update Magnitude: 0.06326
Value Function Update Magnitude: 0.06185
Collected Steps per Second: 6,995.55199
Overall Steps per Second: 4,869.96309
Timestep Collection Time: 7.14826
Timestep Consumption Time: 3.11999
PPO Batch Consumption Time: 0.54229
Total Iteration Time: 10.26825
Cumulative Model Updates: 55
Cumulative Timesteps: 1,000,122
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1000122...
Checkpoint 1000122 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00116
Policy Entropy: 0.73577
Value Function Loss: 0.03731
Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.02901
Policy Update Magnitude: 0.06181
Value Function Update Magnitude: 0.05946
Collected Steps per Second: 6,851.43168
Overall Steps per Second: 4,867.18732
Timestep Collection Time: 7.30037
Timestep Consumption Time: 2.97620
PPO Batch Consumption Time: 0.53555
Total Iteration Time: 10.27657
Cumulative Model Updates: 58
Cumulative Timesteps: 1,050,140
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01269
Policy Entropy: 0.72021
Value Function Loss: 0.04310
Mean KL Divergence: 0.00453
SB3 Clip Fraction: 0.05519
Policy Update Magnitude: 0.06183
Value Function Update Magnitude: 0.06335
Collected Steps per Second: 7,039.74609
Overall Steps per Second: 4,925.17401
Timestep Collection Time: 7.10338
Timestep Consumption Time: 3.04976
PPO Batch Consumption Time: 0.53493
Total Iteration Time: 10.15314
Cumulative Model Updates: 61
Cumulative Timesteps: 1,100,146
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 1100146...
Checkpoint 1100146 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02535
Policy Entropy: 0.70947
Value Function Loss: 0.06142
Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.05140
Policy Update Magnitude: 0.05728
Value Function Update Magnitude: 0.07143
Collected Steps per Second: 6,848.34312
Overall Steps per Second: 4,800.03371
Timestep Collection Time: 7.30279
Timestep Consumption Time: 3.11631
PPO Batch Consumption Time: 0.54853
Total Iteration Time: 10.41909
Cumulative Model Updates: 64
Cumulative Timesteps: 1,150,158
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00029
Policy Entropy: 0.70360
Value Function Loss: 0.04659
Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.00661
Policy Update Magnitude: 0.06044
Value Function Update Magnitude: 0.07497
Collected Steps per Second: 6,765.74930
Overall Steps per Second: 4,758.21853
Timestep Collection Time: 7.39194
Timestep Consumption Time: 3.11872
PPO Batch Consumption Time: 0.55355
Total Iteration Time: 10.51066
Cumulative Model Updates: 67
Cumulative Timesteps: 1,200,170
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1200170...
Checkpoint 1200170 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01135
Policy Entropy: 0.69745
Value Function Loss: 0.05286
Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.01083
Policy Update Magnitude: 0.06366
Value Function Update Magnitude: 0.08091
Collected Steps per Second: 6,935.68293
Overall Steps per Second: 4,850.40601
Timestep Collection Time: 7.20996
Timestep Consumption Time: 3.09969
PPO Batch Consumption Time: 0.54835
Total Iteration Time: 10.30965
Cumulative Model Updates: 70
Cumulative Timesteps: 1,250,176
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05221
Policy Entropy: 0.69005
Value Function Loss: 0.03659
Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.02577
Policy Update Magnitude: 0.06293
Value Function Update Magnitude: 0.08078
Collected Steps per Second: 6,787.17860
Overall Steps per Second: 4,811.14528
Timestep Collection Time: 7.36830
Timestep Consumption Time: 3.02631
PPO Batch Consumption Time: 0.54572
Total Iteration Time: 10.39461
Cumulative Model Updates: 73
Cumulative Timesteps: 1,300,186
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1300186...
Checkpoint 1300186 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00218
Policy Entropy: 0.68332
Value Function Loss: 0.05185
Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.02441
Policy Update Magnitude: 0.06204
Value Function Update Magnitude: 0.07815
Collected Steps per Second: 7,059.75944
Overall Steps per Second: 4,955.35846
Timestep Collection Time: 7.08239
Timestep Consumption Time: 3.00769
PPO Batch Consumption Time: 0.52232
Total Iteration Time: 10.09009
Cumulative Model Updates: 76
Cumulative Timesteps: 1,350,186
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00380
Policy Entropy: 0.67850
Value Function Loss: 0.05268
Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.02827
Policy Update Magnitude: 0.06348
Value Function Update Magnitude: 0.07869
Collected Steps per Second: 6,987.20949
Overall Steps per Second: 4,906.06594
Timestep Collection Time: 7.15765
Timestep Consumption Time: 3.03626
PPO Batch Consumption Time: 0.53552
Total Iteration Time: 10.19391
Cumulative Model Updates: 79
Cumulative Timesteps: 1,400,198
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1400198...
Checkpoint 1400198 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02802
Policy Entropy: 0.67468
Value Function Loss: 0.06768
Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02347
Policy Update Magnitude: 0.06148
Value Function Update Magnitude: 0.08262
Collected Steps per Second: 6,947.41515
Overall Steps per Second: 4,857.17977
Timestep Collection Time: 7.19922
Timestep Consumption Time: 3.09811
PPO Batch Consumption Time: 0.54455
Total Iteration Time: 10.29733
Cumulative Model Updates: 82
Cumulative Timesteps: 1,450,214
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04371
Policy Entropy: 0.67102
Value Function Loss: 0.06326
Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02038
Policy Update Magnitude: 0.06613
Value Function Update Magnitude: 0.08406
Collected Steps per Second: 6,611.37726
Overall Steps per Second: 4,678.42638
Timestep Collection Time: 7.56454
Timestep Consumption Time: 3.12538
PPO Batch Consumption Time: 0.54101
Total Iteration Time: 10.68992
Cumulative Model Updates: 85
Cumulative Timesteps: 1,500,226
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
Saving checkpoint 1500226...
Checkpoint 1500226 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00795
Policy Entropy: 0.66447
Value Function Loss: 0.08821
Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.02403
Policy Update Magnitude: 0.06318
Value Function Update Magnitude: 0.08498
Collected Steps per Second: 6,594.82693
Overall Steps per Second: 4,628.36720
Timestep Collection Time: 7.58170
Timestep Consumption Time: 3.22125
PPO Batch Consumption Time: 0.58619
Total Iteration Time: 10.80295
Cumulative Model Updates: 88
Cumulative Timesteps: 1,550,226
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02936
Policy Entropy: 0.65982
Value Function Loss: 0.09052
Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.01010
Policy Update Magnitude: 0.06716
Value Function Update Magnitude: 0.08607
Collected Steps per Second: 6,746.91743
Overall Steps per Second: 4,715.44283
Timestep Collection Time: 7.41227
Timestep Consumption Time: 3.19330
PPO Batch Consumption Time: 0.55783
Total Iteration Time: 10.60558
Cumulative Model Updates: 91
Cumulative Timesteps: 1,600,236
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 1600236...
Checkpoint 1600236 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00773
Policy Entropy: 0.65979
Value Function Loss: 0.08551
Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.01241
Policy Update Magnitude: 0.07129
Value Function Update Magnitude: 0.08325
Collected Steps per Second: 6,806.46680
Overall Steps per Second: 4,740.87675
Timestep Collection Time: 7.34772
Timestep Consumption Time: 3.20139
PPO Batch Consumption Time: 0.57064
Total Iteration Time: 10.54910
Cumulative Model Updates: 94
Cumulative Timesteps: 1,650,248
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03240
Policy Entropy: 0.66724
Value Function Loss: 0.07504
Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.01947
Policy Update Magnitude: 0.07244
Value Function Update Magnitude: 0.07109
Collected Steps per Second: 7,006.54529
Overall Steps per Second: 4,947.03082
Timestep Collection Time: 7.13733
Timestep Consumption Time: 2.97136
PPO Batch Consumption Time: 0.52479
Total Iteration Time: 10.10869
Cumulative Model Updates: 97
Cumulative Timesteps: 1,700,256
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1700256...
Checkpoint 1700256 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07077
Policy Entropy: 0.67546
Value Function Loss: 0.06948
Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.02829
Policy Update Magnitude: 0.07179
Value Function Update Magnitude: 0.07025
Collected Steps per Second: 6,674.91144
Overall Steps per Second: 4,724.51615
Timestep Collection Time: 7.49193
Timestep Consumption Time: 3.09285
PPO Batch Consumption Time: 0.53022
Total Iteration Time: 10.58479
Cumulative Model Updates: 100
Cumulative Timesteps: 1,750,264
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01230
Policy Entropy: 0.67786
Value Function Loss: 0.05410
Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.03920
Policy Update Magnitude: 0.06854
Value Function Update Magnitude: 0.07025
Collected Steps per Second: 6,973.71427
Overall Steps per Second: 4,892.56273
Timestep Collection Time: 7.17035
Timestep Consumption Time: 3.05006
PPO Batch Consumption Time: 0.53629
Total Iteration Time: 10.22041
Cumulative Model Updates: 103
Cumulative Timesteps: 1,800,268
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 1800268...
Checkpoint 1800268 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03560
Policy Entropy: 0.67528
Value Function Loss: 0.05960
Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.03340
Policy Update Magnitude: 0.06402
Value Function Update Magnitude: 0.06927
Collected Steps per Second: 6,895.06068
Overall Steps per Second: 4,829.26874
Timestep Collection Time: 7.25157
Timestep Consumption Time: 3.10197
PPO Batch Consumption Time: 0.53984
Total Iteration Time: 10.35353
Cumulative Model Updates: 106
Cumulative Timesteps: 1,850,268
Timesteps Collected: 50,000
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01586
Policy Entropy: 0.67447
Value Function Loss: 0.04212
Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.01283
Policy Update Magnitude: 0.06267
Value Function Update Magnitude: 0.06832
Collected Steps per Second: 6,688.06765
Overall Steps per Second: 4,717.91878
Timestep Collection Time: 7.47720
Timestep Consumption Time: 3.12239
PPO Batch Consumption Time: 0.54111
Total Iteration Time: 10.59959
Cumulative Model Updates: 109
Cumulative Timesteps: 1,900,276
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
Saving checkpoint 1900276...
Checkpoint 1900276 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00423
Policy Entropy: 0.67236
Value Function Loss: 0.05166
Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.00941
Policy Update Magnitude: 0.06304
Value Function Update Magnitude: 0.06956
Collected Steps per Second: 6,883.53822
Overall Steps per Second: 4,790.28907
Timestep Collection Time: 7.26487
Timestep Consumption Time: 3.17459
PPO Batch Consumption Time: 0.57224
Total Iteration Time: 10.43945
Cumulative Model Updates: 112
Cumulative Timesteps: 1,950,284
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00222
Policy Entropy: 0.66736
Value Function Loss: 0.04111
Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.01073
Policy Update Magnitude: 0.06319
Value Function Update Magnitude: 0.06398
Collected Steps per Second: 6,363.38016
Overall Steps per Second: 4,516.28633
Timestep Collection Time: 7.85840
Timestep Consumption Time: 3.21397
PPO Batch Consumption Time: 0.57191
Total Iteration Time: 11.07237
Cumulative Model Updates: 115
Cumulative Timesteps: 2,000,290
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 2000290...
Checkpoint 2000290 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03493
Policy Entropy: 0.66347
Value Function Loss: 0.05853
Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.03637
Policy Update Magnitude: 0.06236
Value Function Update Magnitude: 0.05933
Collected Steps per Second: 6,446.82051
Overall Steps per Second: 4,624.25633
Timestep Collection Time: 7.75638
Timestep Consumption Time: 3.05703
PPO Batch Consumption Time: 0.52493
Total Iteration Time: 10.81341
Cumulative Model Updates: 118
Cumulative Timesteps: 2,050,294
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00477
Policy Entropy: 0.66328
Value Function Loss: 0.06584
Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.02873
Policy Update Magnitude: 0.06538
Value Function Update Magnitude: 0.06116
Collected Steps per Second: 6,655.94463
Overall Steps per Second: 4,741.25017
Timestep Collection Time: 7.51238
Timestep Consumption Time: 3.03378
PPO Batch Consumption Time: 0.53609
Total Iteration Time: 10.54616
Cumulative Model Updates: 121
Cumulative Timesteps: 2,100,296
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 2100296...
Checkpoint 2100296 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02445
Policy Entropy: 0.66803
Value Function Loss: 0.04955
Mean KL Divergence: 0.00142
SB3 Clip Fraction: 0.00667
Policy Update Magnitude: 0.06567
Value Function Update Magnitude: 0.05915
Collected Steps per Second: 7,006.72697
Overall Steps per Second: 4,879.74787
Timestep Collection Time: 7.13686
Timestep Consumption Time: 3.11080
PPO Batch Consumption Time: 0.52444
Total Iteration Time: 10.24766
Cumulative Model Updates: 124
Cumulative Timesteps: 2,150,302
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01480
Policy Entropy: 0.67142
Value Function Loss: 0.05371
Mean KL Divergence: 0.00132
SB3 Clip Fraction: 0.00356
Policy Update Magnitude: 0.06621
Value Function Update Magnitude: 0.05448
Collected Steps per Second: 6,961.48489
Overall Steps per Second: 4,852.34138
Timestep Collection Time: 7.18295
Timestep Consumption Time: 3.12218
PPO Batch Consumption Time: 0.53701
Total Iteration Time: 10.30513
Cumulative Model Updates: 127
Cumulative Timesteps: 2,200,306
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 2200306...
Checkpoint 2200306 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03671
Policy Entropy: 0.67479
Value Function Loss: 0.05214
Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.00992
Policy Update Magnitude: 0.06640
Value Function Update Magnitude: 0.05309
Collected Steps per Second: 6,056.34401
Overall Steps per Second: 4,283.30961
Timestep Collection Time: 8.25680
Timestep Consumption Time: 3.41782
PPO Batch Consumption Time: 0.59564
Total Iteration Time: 11.67462
Cumulative Model Updates: 130
Cumulative Timesteps: 2,250,312
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02613
Policy Entropy: 0.67930
Value Function Loss: 0.09712
Mean KL Divergence: 0.00182
SB3 Clip Fraction: 0.00710
Policy Update Magnitude: 0.07535
Value Function Update Magnitude: 0.06535
Collected Steps per Second: 6,971.89123
Overall Steps per Second: 4,873.78000
Timestep Collection Time: 7.17252
Timestep Consumption Time: 3.08769
PPO Batch Consumption Time: 0.53203
Total Iteration Time: 10.26021
Cumulative Model Updates: 133
Cumulative Timesteps: 2,300,318
Timesteps Collected: 50,006
--------END ITERATION REPORT--------
Saving checkpoint 2300318...
Checkpoint 2300318 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00478
Policy Entropy: 0.68428
Value Function Loss: 0.08537
Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.02677
Policy Update Magnitude: 0.08254
Value Function Update Magnitude: 0.08006
Collected Steps per Second: 5,949.32446
Overall Steps per Second: 4,300.99803
Timestep Collection Time: 8.40600
Timestep Consumption Time: 3.22154
PPO Batch Consumption Time: 0.57941
Total Iteration Time: 11.62753
Cumulative Model Updates: 136
Cumulative Timesteps: 2,350,328
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01513
Policy Entropy: 0.68436
Value Function Loss: 0.09535
Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02235
Policy Update Magnitude: 0.08659
Value Function Update Magnitude: 0.08028
Collected Steps per Second: 6,796.04256
Overall Steps per Second: 4,747.83915
Timestep Collection Time: 7.35752
Timestep Consumption Time: 3.17401
PPO Batch Consumption Time: 0.57668
Total Iteration Time: 10.53153
Cumulative Model Updates: 139
Cumulative Timesteps: 2,400,330
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
Saving checkpoint 2400330...
Checkpoint 2400330 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02176
Policy Entropy: 0.68100
Value Function Loss: 0.08890
Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.02516
Policy Update Magnitude: 0.08410
Value Function Update Magnitude: 0.07291
Collected Steps per Second: 6,948.88781
Overall Steps per Second: 4,872.99610
Timestep Collection Time: 7.19597
Timestep Consumption Time: 3.06548
PPO Batch Consumption Time: 0.52959
Total Iteration Time: 10.26145
Cumulative Model Updates: 142
Cumulative Timesteps: 2,450,334
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08514
Policy Entropy: 0.68600
Value Function Loss: 0.09958
Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.03222
Policy Update Magnitude: 0.08589
Value Function Update Magnitude: 0.06946
Collected Steps per Second: 6,332.36546
Overall Steps per Second: 4,584.92839
Timestep Collection Time: 7.89752
Timestep Consumption Time: 3.00995
PPO Batch Consumption Time: 0.53652
Total Iteration Time: 10.90748
Cumulative Model Updates: 145
Cumulative Timesteps: 2,500,344
Timesteps Collected: 50,010
--------END ITERATION REPORT--------
Saving checkpoint 2500344...
Checkpoint 2500344 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00459
Policy Entropy: 0.69162
Value Function Loss: 0.08094
Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.02833
Policy Update Magnitude: 0.08527
Value Function Update Magnitude: 0.06919
Collected Steps per Second: 6,570.33556
Overall Steps per Second: 4,654.75826
Timestep Collection Time: 7.61087
Timestep Consumption Time: 3.13211
PPO Batch Consumption Time: 0.54741
Total Iteration Time: 10.74299
Cumulative Model Updates: 148
Cumulative Timesteps: 2,550,350
Timesteps Collected: 50,006
