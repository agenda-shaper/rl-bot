Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08514
Policy Entropy: 0.68838
Value Function Loss: 0.01070
Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.02669
Value Function Update Magnitude: 0.02365
Collected Steps per Second: 8,110.02965
Overall Steps per Second: 6,174.08509
Timestep Collection Time: 6.16890
Timestep Consumption Time: 1.93432
PPO Batch Consumption Time: 0.72323
Total Iteration Time: 8.10322
Cumulative Model Updates: 146
Cumulative Timesteps: 2,550,374
Timesteps Collected: 50,030
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.22712
Policy Entropy: 0.68742
Value Function Loss: 0.00855
Mean KL Divergence: 0.00034
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.04771
Value Function Update Magnitude: 0.04043
Collected Steps per Second: 7,601.73683
Overall Steps per Second: 5,469.70618
Timestep Collection Time: 6.57981
Timestep Consumption Time: 2.56474
PPO Batch Consumption Time: 0.57207
Total Iteration Time: 9.14455
Cumulative Model Updates: 148
Cumulative Timesteps: 2,600,392
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 2600392...
Checkpoint 2600392 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12106
Policy Entropy: 0.68111
Value Function Loss: 0.00781
Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.01073
Policy Update Magnitude: 0.06122
Value Function Update Magnitude: 0.05755
Collected Steps per Second: 8,272.65192
Overall Steps per Second: 5,709.58472
Timestep Collection Time: 6.04643
Timestep Consumption Time: 2.71428
PPO Batch Consumption Time: 0.51670
Total Iteration Time: 8.76071
Cumulative Model Updates: 151
Cumulative Timesteps: 2,650,412
Timesteps Collected: 50,020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.17450
Policy Entropy: 0.67339
Value Function Loss: 0.00673
Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02442
Policy Update Magnitude: 0.05116
Value Function Update Magnitude: 0.05337
Collected Steps per Second: 8,422.74651
Overall Steps per Second: 5,769.43798
Timestep Collection Time: 5.93892
Timestep Consumption Time: 2.73125
PPO Batch Consumption Time: 0.51396
Total Iteration Time: 8.67017
Cumulative Model Updates: 154
Cumulative Timesteps: 2,700,434
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 2700434...
Checkpoint 2700434 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13282
Policy Entropy: 0.67473
Value Function Loss: 0.00591
Mean KL Divergence: 0.00092
SB3 Clip Fraction: 0.00139
Policy Update Magnitude: 0.04951
Value Function Update Magnitude: 0.04867
Collected Steps per Second: 8,548.97502
Overall Steps per Second: 5,761.11167
Timestep Collection Time: 5.84889
Timestep Consumption Time: 2.83034
PPO Batch Consumption Time: 0.51593
Total Iteration Time: 8.67923
Cumulative Model Updates: 157
Cumulative Timesteps: 2,750,436
Timesteps Collected: 50,002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.32485
Policy Entropy: 0.67966
Value Function Loss: 0.01378
Mean KL Divergence: 0.00090
SB3 Clip Fraction: 0.00203
Policy Update Magnitude: 0.05040
Value Function Update Magnitude: 0.04430
Collected Steps per Second: 8,587.98715
Overall Steps per Second: 5,760.10509
Timestep Collection Time: 5.82535
Timestep Consumption Time: 2.85991
PPO Batch Consumption Time: 0.51697
Total Iteration Time: 8.68526
Cumulative Model Updates: 160
Cumulative Timesteps: 2,800,464
Timesteps Collected: 50,028
--------END ITERATION REPORT--------
Saving checkpoint 2800464...
Checkpoint 2800464 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.21285
Policy Entropy: 0.68768
Value Function Loss: 0.01405
Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.01137
Policy Update Magnitude: 0.05149
Value Function Update Magnitude: 0.04536
Collected Steps per Second: 8,635.00112
Overall Steps per Second: 5,823.82711
Timestep Collection Time: 5.79178
Timestep Consumption Time: 2.79570
PPO Batch Consumption Time: 0.51162
Total Iteration Time: 8.58748
Cumulative Model Updates: 163
Cumulative Timesteps: 2,850,476
Timesteps Collected: 50,012
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04538
Policy Entropy: 0.69582
Value Function Loss: 0.01422
Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.01515
Policy Update Magnitude: 0.05554
Value Function Update Magnitude: 0.05137
Collected Steps per Second: 8,563.50221
Overall Steps per Second: 5,766.97419
Timestep Collection Time: 5.84130
Timestep Consumption Time: 2.83257
PPO Batch Consumption Time: 0.51704
Total Iteration Time: 8.67387
Cumulative Model Updates: 166
Cumulative Timesteps: 2,900,498
Timesteps Collected: 50,022
--------END ITERATION REPORT--------
Saving checkpoint 2900498...
Checkpoint 2900498 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.34560
Policy Entropy: 0.69757
Value Function Loss: 0.00478
Mean KL Divergence: 0.00169
SB3 Clip Fraction: 0.00726
Policy Update Magnitude: 0.05248
Value Function Update Magnitude: 0.04679
Collected Steps per Second: 7,844.56260
Overall Steps per Second: 5,362.97432
Timestep Collection Time: 6.37588
Timestep Consumption Time: 2.95029
PPO Batch Consumption Time: 0.54267
Total Iteration Time: 9.32617
Cumulative Model Updates: 169
Cumulative Timesteps: 2,950,514
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.18332
Policy Entropy: 0.69775
Value Function Loss: 0.00667
Mean KL Divergence: 0.00131
SB3 Clip Fraction: 0.00391
Policy Update Magnitude: 0.04882
Value Function Update Magnitude: 0.04306
Collected Steps per Second: 7,252.63253
Overall Steps per Second: 5,126.44936
Timestep Collection Time: 6.89653
Timestep Consumption Time: 2.86032
PPO Batch Consumption Time: 0.51904
Total Iteration Time: 9.75685
Cumulative Model Updates: 172
Cumulative Timesteps: 3,000,532
Timesteps Collected: 50,018
--------END ITERATION REPORT--------
Saving checkpoint 3000532...
Checkpoint 3000532 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04855
Policy Entropy: 0.70070
Value Function Loss: 0.00712
Mean KL Divergence: 0.00108
SB3 Clip Fraction: 0.00280
Policy Update Magnitude: 0.04976
Value Function Update Magnitude: 0.04263
Collected Steps per Second: 8,365.03406
Overall Steps per Second: 5,581.19873
Timestep Collection Time: 5.97917
Timestep Consumption Time: 2.98234
PPO Batch Consumption Time: 0.57251
Total Iteration Time: 8.96152
Cumulative Model Updates: 175
Cumulative Timesteps: 3,050,548
Timesteps Collected: 50,016
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.33118
Policy Entropy: 0.70711
Value Function Loss: 0.00831
Mean KL Divergence: 0.00091
SB3 Clip Fraction: 0.00129
Policy Update Magnitude: 0.05056
Value Function Update Magnitude: 0.04757
Collected Steps per Second: 8,211.82033
Overall Steps per Second: 5,581.24576
Timestep Collection Time: 6.09366
Timestep Consumption Time: 2.87209
PPO Batch Consumption Time: 0.51473
Total Iteration Time: 8.96574
Cumulative Model Updates: 178
Cumulative Timesteps: 3,100,588
Timesteps Collected: 50,040
--------END ITERATION REPORT--------
Saving checkpoint 3100588...
Checkpoint 3100588 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07793
Policy Entropy: 0.72077
Value Function Loss: 0.00700
Mean KL Divergence: 0.00134
SB3 Clip Fraction: 0.00363
Policy Update Magnitude: 0.05587
Value Function Update Magnitude: 0.04818
Collected Steps per Second: 8,562.12817
Overall Steps per Second: 5,757.15784
Timestep Collection Time: 5.84411
Timestep Consumption Time: 2.84733
PPO Batch Consumption Time: 0.51693
Total Iteration Time: 8.69144
Cumulative Model Updates: 181
Cumulative Timesteps: 3,150,626
Timesteps Collected: 50,038
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.31253
Policy Entropy: 0.73775
Value Function Loss: 0.00656
Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.02291
Policy Update Magnitude: 0.05850
Value Function Update Magnitude: 0.04730
Collected Steps per Second: 8,109.18264
Overall Steps per Second: 5,564.55278
Timestep Collection Time: 6.16634
Timestep Consumption Time: 2.81982
PPO Batch Consumption Time: 0.51519
Total Iteration Time: 8.98617
Cumulative Model Updates: 184
Cumulative Timesteps: 3,200,630
Timesteps Collected: 50,004
--------END ITERATION REPORT--------
Saving checkpoint 3200630...
Checkpoint 3200630 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02334
Policy Entropy: 0.75332
Value Function Loss: 0.00586
Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.03739
Policy Update Magnitude: 0.05170
Value Function Update Magnitude: 0.04941
Collected Steps per Second: 8,390.32740
Overall Steps per Second: 5,652.80498
Timestep Collection Time: 5.96020
Timestep Consumption Time: 2.88639
PPO Batch Consumption Time: 0.54241
Total Iteration Time: 8.84658
Cumulative Model Updates: 187
Cumulative Timesteps: 3,250,638
Timesteps Collected: 50,008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.29628
Policy Entropy: 0.75587
Value Function Loss: 0.00798
Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.01125
Policy Update Magnitude: 0.05441
Value Function Update Magnitude: 0.05201
Collected Steps per Second: 8,181.17047
Overall Steps per Second: 5,568.84349
Timestep Collection Time: 6.11453
Timestep Consumption Time: 2.86831
PPO Batch Consumption Time: 0.51776
Total Iteration Time: 8.98283
Cumulative Model Updates: 190
Cumulative Timesteps: 3,300,662
Timesteps Collected: 50,024
--------END ITERATION REPORT--------
Saving checkpoint 3300662...
Checkpoint 3300662 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13821
Policy Entropy: 0.76199
Value Function Loss: 0.01018
Mean KL Divergence: 0.00131
SB3 Clip Fraction: 0.00216
Policy Update Magnitude: 0.06493
Value Function Update Magnitude: 0.05615
Collected Steps per Second: 8,021.68626
Overall Steps per Second: 5,482.91294
Timestep Collection Time: 6.23709
Timestep Consumption Time: 2.88798
PPO Batch Consumption Time: 0.53972
Total Iteration Time: 9.12508
Cumulative Model Updates: 193
Cumulative Timesteps: 3,350,694
Timesteps Collected: 50,032
